# -*- coding: utf-8 -*-
"""vc_crawl.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/155zGvLsUndVsu-dvka9dWGylVSMdu20b
"""

'''
!pip install crawl4ai playwright

!playwright install chromium

'''

import asyncio
from crawl4ai import AsyncWebCrawler
import re

async def extract_all_million_markdown():
    print("Extracting million-funded startups from ALL pages...")

    all_million_markdown = []
    page = 1
    has_more_pages = True

    async with AsyncWebCrawler() as crawler:
        while has_more_pages:
            print(f"üìÑ Crawling page {page}...")

            if page == 1:
                url = "https://www.eu-startups.com/category/spain-startups/"
            else:
                url = f"https://www.eu-startups.com/category/spain-startups/page/{page}/"

            result = await crawler.arun(url)

            # Check if page exists
            if "page not found" in result.markdown.lower() or "404" in result.markdown.lower():
                print(f" Page {page} doesn't exist. Stopping.")
                has_more_pages = False
                break

            # Extract links and filter for million-funded (case insensitive)
            links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', result.markdown)

            page_million_md = []
            for text, url in links:
                if 'million' in text.lower() or 'Million' in text:
                    md_entry = f"## {text}\n**URL:** {url}\n**Source:** EU-Startups Spain Page {page}\n---"
                    page_million_md.append(md_entry)

            if page_million_md:
                print(f" Page {page}: Found {len(page_million_md)} million-funded startups")
                all_million_markdown.extend(page_million_md)
                page += 1
            else:
                print(f" No million-funded startups found on page {page}. Stopping.")
                has_more_pages = False

    return all_million_markdown

all_million_markdown = await extract_all_million_markdown()

# Convert extracted data to clean markdown
print("\n" + "="*80)
print("CONVERTING TO MARKDOWN FORMAT:")
print("="*80)

# Create structured markdown
markdown_content = "# Million-Funded Spanish Startups\n\n"
markdown_content += "## Investment Opportunities from EU-Startups\n\n"

for i, startup in enumerate(all_million_markdown, 1):
    markdown_content += f"{startup}\n\n"

print(f"üìù Converted {len(all_million_markdown)} startups to markdown format")

# Show sample of the markdown
print("\n" + "="*80)
print("MARKDOWN SAMPLE (First 3 entries):")
print("="*80)

for i, startup in enumerate(all_million_markdown[:3], 1):
    print(f"\nEntry {i}:")
    print(startup)

# Save to file
with open("spanish_million_startups.md", "w", encoding="utf-8") as f:
    f.write(markdown_content)

print(f"\nüíæ Saved {len(all_million_markdown)} startups to 'spanish_million_startups.md'")
print("‚úÖ Markdown conversion complete!")